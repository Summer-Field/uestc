# 数据采集方法

- 什么是大数据采集？

从传感器和智能设备、企业在线系统、企业离线系统、社交网络和互联网平台等**获取数据的过程**。

- 技术挑战

数据的可靠性、高效性

避免重复数据

- 数据采集方式

系统日志采集

网络数据采集

数据接口采集

## 3.1 系统日志数据采集

### 什么是系统日志？

- 计算机中的任何数据都可以输出日志（kernel、app服务器）
- Web日志包含（其阿奴单产生的访问日志、app输出日志）
- Web日志中的每条都代表着用户的一次访问行为
- 可以反映很多有用信息（IP、time、客户端信息...）

### 系统日志数据采集目的

- 主要目的：日志分析
  - 排行榜、页面停留最长时间、广告点击模型、用户行为特征分析
  - 构建广告点击量模型、用户行为特征分析

### 系统日志数据采集工具

- Awstats、Webalizer
- 嵌套在js代码：Google Analytics、Cnzz

### 系统日志数据采集过程

日志主机基于Unix或者Windows服务器，他来集中存储日志消息

日志主句可以集中**存储**多个数据源的日志消息，可以对系统日志进行**备份**、可以**分析**日志数据

1. 日志消息通过`syslog`协议传输到日志主机（TCP/UDP都支持）
2. 日志主机的主要工作就是通过`syslog`来采集日志消息，存储到本地磁盘上，进行备份、存储、分析

## 3.2 网络数据采集

### 通用搜索引擎的局限性

- 大量无用网页信息
- 有限服务资源和无线网络数据资源矛盾
- 无法对信息含量密集以及具有一定结构的数据获取
- 不能支持予以查询、检索

### 网络爬虫工作原理

- 爬虫根据确定的目标，**选择性**地抓取某一特定主题相关的网页，为面向主题的用户查询准备数据资源
- 技术框架
  - 控制器：为不同的线程分配工作，调度爬虫的线程资源
  - 解析器：批量下载网页、对页面格式、内容批处理
  - 资源库：存储下载到的网页资源

1. 从初始网页的URL开始，根据网页分析算法**过滤与主题无关的链接**保留有用的链接放入待抓取URL队列
2. 网络爬虫**根据某种搜索策略**从队列中选择下一次要抓取的网页URL，重复上述过程，直到达到某一条件（市场、页面数阈值）

#### 网络搜索策略

- 深度优先

  首先跳转进入起始网页的URL链接，分析这个网页中所包含的URL链接，选择其中一个URL链接进入。如此一个链接一个链接地选择并跳转进入，直到访问完路径中的最后一个URL。之后再回到上一层URL链接，处理下一条路径。

- 广度优先

  在抓取URL的过程中，只有完成当前层级的搜索后，才跳转到下一层级进行搜索。

- 最佳有限

  基于降低广度优先搜索策略的算法复杂度而进行优化的。最佳优先搜索策略按照特定的网页分析算法，**预测候选URL与主题的相关性**，筛选并抓取最相关的某些URL

#### 网页分析算法

**基于拓扑的网页分析算法**是基于网页之间的链接，通过已知的网页，对于其有直接或者间接关系的对象做出评价的算法

- 网页粒度算法

  PageRank是最常见的网页粒度分析算法，PageRank通过某页面所有的超链接关系来确定一个页面的重要等级。它把从A页面到B页面的链接解释为A页面给B页面投票，并根据投票来源和投票目标的等级来决定新的页面的等级。

- 网站粒度算法

  算法实现的关键在于**站点的划分和站点等级SiteRank的计算**。SiteRank的计算方法与PageRank类似，但是需要对网站之间的链接作一定程度的抽象，并在一定的模型下计算链接的权重。

- 网页块粒度算法

  在一个页面中，往往含有多个指向其他页面的链接，这些链接中只有一部分是指向主题相关网页的。**基本思想是将网页分割为不同的网页块**，然后对这些网页块建立链接矩阵。

### 网络爬虫框架

**RBSE** （Eichmann 1994）是第一个发布的爬虫。它有两个基础程序。第一个是“spider”，抓取网页中的URL，并存储到一个关系数据库中；第二个程序是“mite”，它是一个修改后www的ASCII浏览器，负责从网络中下载页面。

**WebCrawler**（Pinkerton 1994）是第一个公开可用的建立全文索引的程序，它使用库www来下载页面，使用广度优先来解析获取URL，并对其进行排序。此外，它还包括一个根据选定文本和查询相似程度爬行的实时爬虫。网络数据采集

**World Wide Web Worm** (McBryan 1994) 为文件建立包括标题和URL简单索引的爬虫，其索引可以通过grep式的Unix命令来实现。

**Google Crawler** (Brin and Page 1998) 集成了索引处理，支持全文检索和URL抽取。它拥有一个URL服务器，用来提供发送爬虫程序时要抓取的URL列表。在文本解析的时候，URL服务器负责检测某个新的URL是否已经存在。如果不存在的话，就将此URL加入到URL服务器中。

## 3.3 数据采集接口

统一的机制来方便不同的前端设备与后端设备进行数据通信

API架构的流行，导致“API First”的设计思想。REST API是目前比较成熟的一套互联网应用程序的API设计理论

- REST 从资源的角度来观察整个网络，分布在各处的资源又URL定位，客户端app通过URL来获取资源。随着不断访问URL来获取资源，客户端app不断转换状态
- REST基于HTTP、URL、XML、HTML流行的**协议和标准**
- REST对资源的操作包括“获取、创建、修改、删除”  --  “GET、POST、PUT、DELETE”